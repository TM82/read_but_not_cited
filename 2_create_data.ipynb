{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T11:33:10.683969Z",
     "start_time": "2023-06-11T11:33:10.673549Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:17.817379Z",
     "iopub.status.busy": "2024-02-17T12:30:17.816545Z",
     "iopub.status.idle": "2024-02-17T12:30:18.435637Z",
     "shell.execute_reply": "2024-02-17T12:30:18.434808Z",
     "shell.execute_reply.started": "2024-02-17T12:30:17.817326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config.ini', encoding='utf-8')\n",
    "SAVE_DIR = config.get('settings','SAVE_DIR')\n",
    "WORK_DIR = config.get('settings','WORK_DIR')\n",
    "SHARE_DIR = config.get('settings','SHARE_DIR')\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings.read('./settings.ini', encoding='utf-8')\n",
    "MIN_YEAR = int(settings.get('experiment','MIN_YEAR'))\n",
    "MAX_YEAR = int(settings.get('experiment','MAX_YEAR'))\n",
    "RESOLUTION = float(settings.get('experiment','RESOLUTION'))\n",
    "NMIN = int(settings.get('experiment','NMIN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T07:37:29.760556Z",
     "start_time": "2023-06-08T07:37:29.509082Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:18.436992Z",
     "iopub.status.busy": "2024-02-17T12:30:18.436770Z",
     "iopub.status.idle": "2024-02-17T12:30:18.629570Z",
     "shell.execute_reply": "2024-02-17T12:30:18.628640Z",
     "shell.execute_reply.started": "2024-02-17T12:30:18.436976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: nan,\n",
       " 0: 'Molecular & Cellular Biology',\n",
       " 1: 'Neuropsychiatric Disorders',\n",
       " 2: 'Organic & Inorganic Chemistry',\n",
       " 3: 'Social & Political Sciences',\n",
       " 4: 'Ecology & Evolution',\n",
       " 5: 'Nutrition & Microbiome',\n",
       " 6: 'Nanomaterials & Energy Storage',\n",
       " 7: 'Computer Vision & Security',\n",
       " 8: 'Cardiovascular Medicine',\n",
       " 9: 'Wireless Networks & Security',\n",
       " 10: 'Biomaterials & Orthopedics',\n",
       " 11: 'Fluid Mechanics & Heat Transfer',\n",
       " 12: 'Astronomy & Astrophysics',\n",
       " 13: 'Environmental Science & Technology',\n",
       " 14: 'Information & Computer Science',\n",
       " 15: 'Materials Science & Engineering',\n",
       " 16: 'Plant Science & Stress Responses',\n",
       " 17: 'Quantum Physics & Superconductivity',\n",
       " 18: 'Geology & Tectonics',\n",
       " 19: 'Climate Science & Remote Sensing',\n",
       " 20: 'Gastroenterology & Surgery',\n",
       " 21: 'Respiratory & Critical Care Medicine',\n",
       " 22: 'Power Systems & Smart Grids',\n",
       " 23: 'Structural Engineering & Materials',\n",
       " 24: 'Metamaterials & Antennas',\n",
       " 25: 'Vibration & Material Mechanics',\n",
       " 26: 'Control Systems & Robustness',\n",
       " 27: 'Optics & Photonics',\n",
       " 28: 'Autoimmune & Inflammatory Diseases',\n",
       " 29: 'Healthcare & Medical Education',\n",
       " 30: 'Semiconductor Materials & Devices',\n",
       " 31: 'Wireless Communications & MIMO',\n",
       " 32: 'History & Cultural Studies',\n",
       " 33: 'Operations Research & Logistics',\n",
       " 34: 'Orthopedics & Biomechanics',\n",
       " 35: 'Virology & Vaccines',\n",
       " 36: 'String Theory & Supersymmetry',\n",
       " 37: 'Urology & Pelvic Health',\n",
       " 38: 'Nonlinear Analysis & Fixed Points',\n",
       " 39: 'Infectious Diseases & HIV',\n",
       " 40: 'Ophthalmology & Vision Disorders',\n",
       " 41: 'Neurosurgical Disorders',\n",
       " 42: 'Obstetrics & Gynecology',\n",
       " 43: 'Parasitic Diseases',\n",
       " 44: 'Machining & Manufacturing',\n",
       " 45: 'Plasma Physics & Fusion',\n",
       " 46: 'Classics & Ancient History',\n",
       " 47: 'Laser & Plasma Physics',\n",
       " 48: 'Infectious Ear Diseases',\n",
       " 49: 'Reproductive Health & Cancer',\n",
       " 50: 'Thyroid & Head-Neck Surgery',\n",
       " 51: 'Science & Engineering Education',\n",
       " 52: 'Soft Tissue & Bone Tumors',\n",
       " 53: 'Linguistics & Multilingualism',\n",
       " 54: 'Biomass & Pyrolysis',\n",
       " 55: 'Breast Diseases & Surgery',\n",
       " 56: 'Transportation & Traffic Engineering',\n",
       " 57: 'Statistical Methods & Theory',\n",
       " 58: 'Philosophy & Metaphysics',\n",
       " 59: 'Inherited Blood Disorders',\n",
       " 60: 'Fungal Infections',\n",
       " 61: 'Animal Breeding & Reproduction',\n",
       " 62: 'Scientometrics & Research Ethics',\n",
       " 63: 'Chemical Engineering & Phase Equilibria',\n",
       " 64: 'Polymer Science & Engineering',\n",
       " 65: 'Neurological & Immunological Disorders'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = pd.read_excel(\n",
    "     SAVE_DIR+f'paper_detail/keywords_in_2021_{RESOLUTION}_{NMIN}_tficf_waltman_name.xlsx', \n",
    "     sheet_name='names'\n",
    " )[['partition','n_1970-2021','n_2016','nameByGPT-4'] + [f'word{i}' for i in range(5)]]\n",
    "keywords = {int(k):v for k,v in _.set_index('partition')['nameByGPT-4'].to_dict().items()}\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.694213Z",
     "start_time": "2023-06-04T02:14:19.790152Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:18.630755Z",
     "iopub.status.busy": "2024-02-17T12:30:18.630529Z",
     "iopub.status.idle": "2024-02-17T12:30:49.115987Z",
     "shell.execute_reply": "2024-02-17T12:30:49.115022Z",
     "shell.execute_reply.started": "2024-02-17T12:30:18.630740Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016年の全データ (3053383, 12)\n",
      "ar,cp,re,le,edのいずれかのデータ 2747241\n"
     ]
    }
   ],
   "source": [
    "papers_2016 = pd.merge(\n",
    "    pd.concat([\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/eid_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/authids_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/subjs_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/doi_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/doctype_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/journal_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/c_history_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/c_history_sum_2016.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+f'paper_detail_2016/c_normalized_in_2021_{RESOLUTION}_{NMIN}_2016_waltman.pickle'),\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail_2016/CD_2016.pickle'),\n",
    "    ],axis=1),\n",
    "    pd.read_pickle(SAVE_DIR+f'paper_detail/partition_in_2021_{RESOLUTION}_{NMIN}_waltman.pickle'),\n",
    "    left_on='eid',right_index=True,how='left'\n",
    ")\n",
    "papers_2016['c_history_sum_2018'] = papers_2016['c_history'].map(lambda l: sum(l[:3]))\n",
    "print('2016年の全データ', papers_2016.shape)\n",
    "\n",
    "# Exclude those that are books (ch, bk), those that are short (sh, er), and those that are comments (no, cr (to be checked later), dp, tb, ip, ab, bz, rp).\n",
    "papers_2016 = papers_2016[papers_2016['doctype'].isin({'ar','cp','re','le','ed'})].copy()\n",
    "print('ar,cp,re,le,edのいずれかのデータ', len(papers_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.738198Z",
     "start_time": "2023-06-04T02:14:57.695908Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.117117Z",
     "iopub.status.busy": "2024-02-17T12:30:49.116956Z",
     "iopub.status.idle": "2024-02-17T12:30:49.146617Z",
     "shell.execute_reply": "2024-02-17T12:30:49.145807Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.117102Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0     4780\n",
      "0.0      284408\n",
      "1.0      203464\n",
      "2.0      131490\n",
      "3.0      164481\n",
      "4.0      127465\n",
      "5.0      113198\n",
      "6.0      128505\n",
      "7.0      107891\n",
      "8.0      61198\n",
      "9.0      76124\n",
      "10.0     62373\n",
      "11.0     59738\n",
      "12.0     44191\n",
      "13.0     51060\n",
      "14.0     61579\n",
      "15.0     45363\n",
      "16.0     43567\n",
      "17.0     31773\n",
      "18.0     40224\n",
      "19.0     41908\n",
      "20.0     31171\n",
      "21.0     30812\n",
      "22.0     50331\n",
      "23.0     37908\n",
      "24.0     35337\n",
      "25.0     29167\n",
      "26.0     27556\n",
      "27.0     23369\n",
      "28.0     20512\n",
      "29.0     22988\n",
      "30.0     17536\n",
      "31.0     28186\n",
      "32.0     20979\n",
      "33.0     26151\n",
      "34.0     22504\n",
      "35.0     16786\n",
      "36.0     17697\n",
      "37.0     17005\n",
      "38.0     19444\n",
      "39.0     15116\n",
      "40.0     13919\n",
      "41.0     12097\n",
      "42.0     11213\n",
      "43.0     10774\n",
      "44.0     15736\n",
      "45.0     12037\n",
      "46.0     10377\n",
      "47.0     11623\n",
      "48.0     7346\n",
      "49.0     8491\n",
      "50.0     7880\n",
      "51.0     8055\n",
      "52.0     6877\n",
      "53.0     8046\n",
      "54.0     8319\n",
      "55.0     6940\n",
      "56.0     9166\n",
      "57.0     5675\n",
      "58.0     5463\n",
      "59.0     3778\n",
      "60.0     3904\n",
      "61.0     2916\n",
      "62.0     4528\n",
      "63.0     2837\n",
      "64.0     2208\n",
      "65.0     3476\n"
     ]
    }
   ],
   "source": [
    "for k,v in papers_2016[f'partition_{RESOLUTION}'].value_counts().sort_index().items():\n",
    "    print(str(k).ljust(8),v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.747355Z",
     "start_time": "2023-06-04T02:14:57.739813Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.148340Z",
     "iopub.status.busy": "2024-02-17T12:30:49.148194Z",
     "iopub.status.idle": "2024-02-17T12:30:49.154160Z",
     "shell.execute_reply": "2024-02-17T12:30:49.153721Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.148327Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_jif():\n",
    "    SHARE_DIR = '/disks/qnap2/shared/scopus_2022/'\n",
    "    _papers =(pd.concat([\n",
    "            pd.read_pickle(SHARE_DIR+'paper_detail/eid.pickle'),\n",
    "            pd.read_pickle(SHARE_DIR+'paper_detail/year.pickle'),\n",
    "            pd.read_pickle(SHARE_DIR+'paper_detail/journal.pickle'),\n",
    "            pd.read_pickle('/disks/qnap2/data/t-miura/2022_fieldmerge/SIGMET/paper_detail/c_history.pickle')\n",
    "        ],axis=1)\n",
    "    )\n",
    "\n",
    "    journal_papers = (_papers[['eid','year','journal','c_history']].set_index('eid')\n",
    "                     .assign(c1=lambda df: df['c_history'].map(lambda c_list: c_list[1] if len(c_list) > 1 else 0))\n",
    "                     .assign(c2=lambda df: df['c_history'].map(lambda c_list: c_list[2] if len(c_list) > 2 else 0))\n",
    "                      [['year','journal','c1','c2']]\n",
    "                     )\n",
    "    journal_counts = journal_papers[['journal','year']].value_counts()\n",
    "    journal_citations = journal_papers.groupby(['journal','year']).agg(np.sum)\n",
    "    journal_citations_c1 = journal_citations['c1'].to_dict()\n",
    "    journal_citations_c2 = journal_citations['c2'].to_dict()\n",
    "\n",
    "    journal_IFs = {\n",
    "        journal_id: {\n",
    "            year: (journal_citations_c1.get((journal_id, year-1), 0) + journal_citations_c2.get((journal_id, year-2), 0)) / (journal_counts.get((journal_id, year-2),0) + journal_counts.get((journal_id, year-1),0))\n",
    "            for year in range(1970,2023) if (journal_counts.get((journal_id, year-2),0) + journal_counts.get((journal_id, year-1),0)) != 0\n",
    "        } for journal_id in tqdm(list(journal_papers['journal'].unique()))\n",
    "    }\n",
    "\n",
    "    # with open('/disks/qnap2/data/t-miura/2023_readership/papers/jif.pickle', 'wb') as f:\n",
    "    #     pickle.dump(journal_IFs, f)\n",
    "\n",
    "#     40分ほど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.750740Z",
     "start_time": "2023-06-04T02:14:57.748356Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.154758Z",
     "iopub.status.busy": "2024-02-17T12:30:49.154625Z",
     "iopub.status.idle": "2024-02-17T12:30:49.157399Z",
     "shell.execute_reply": "2024-02-17T12:30:49.157045Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.154746Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_jif(papers, year):\n",
    "    jif_dic = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/papers/jif.pickle')\n",
    "    papers['jif'] = papers.apply(lambda row: jif_dic[row['journal']].get(year,.0), axis=1)\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.754169Z",
     "start_time": "2023-06-04T02:14:57.751647Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.157994Z",
     "iopub.status.busy": "2024-02-17T12:30:49.157859Z",
     "iopub.status.idle": "2024-02-17T12:30:49.160726Z",
     "shell.execute_reply": "2024-02-17T12:30:49.160362Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.157982Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_partition(papers):\n",
    "    papers = pd.merge(\n",
    "        papers,\n",
    "        pd.read_pickle(SAVE_DIR+'paper_detail/partition_in_2021_0.0005_1000_waltman.pickle'),\n",
    "        left_on='eid', right_index=True, how='left'\n",
    "    )\n",
    "    with open(SAVE_DIR+f'paper_detail/partition_to_ASJC_in_2021_{RESOLUTION}_{NMIN}.pickle','rb') as f:\n",
    "        pid_to_largefield = pickle.load(f)\n",
    "    papers['partition_ASJC'] = papers['partition_1e-06'].map(pid_to_largefield)\n",
    "    \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.758679Z",
     "start_time": "2023-06-04T02:14:57.755119Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.161294Z",
     "iopub.status.busy": "2024-02-17T12:30:49.161170Z",
     "iopub.status.idle": "2024-02-17T12:30:49.165028Z",
     "shell.execute_reply": "2024-02-17T12:30:49.164658Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.161283Z"
    }
   },
   "outputs": [],
   "source": [
    "# readership\n",
    "def get_df(lines):\n",
    "    names = ['eid'] + lines[0].strip('\\n').split('\\t')[1:]\n",
    "    df = pd.DataFrame([l.strip('\\n').split('\\t') for l in lines[1:]], columns=names)\n",
    "    return (df\n",
    "            .astype({k:int for k in names[2:]}) \n",
    "            [df['eid'].map(len) == 18] \n",
    "            .assign(eid=lambda df: df['eid'].map(lambda x: int(x[7:]))) \n",
    "           )\n",
    "\n",
    "def merge_df(papers, readership):\n",
    "    return pd.merge(papers, readership.drop(['doi'],axis=1), on='eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.763985Z",
     "start_time": "2023-06-04T02:14:57.760609Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.165622Z",
     "iopub.status.busy": "2024-02-17T12:30:49.165480Z",
     "iopub.status.idle": "2024-02-17T12:30:49.168940Z",
     "shell.execute_reply": "2024-02-17T12:30:49.168573Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.165610Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_readership(papers):\n",
    "    \n",
    "    with open('/disks/qnap2/data/t-miura/2023_readership/papers/old_waltman_1e-06/DOI_LIST/readership_data/highly_cited_readership.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "        readership_hcp = get_df(lines)\n",
    "    with open('/disks/qnap2/data/t-miura/2023_readership/papers/old_waltman_1e-06/DOI_LIST/readership_data/mid_cited_readership.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "        readership_mcp = get_df(lines)\n",
    "    with open('/disks/qnap2/data/t-miura/2023_readership/papers/old_waltman_1e-06/DOI_LIST/readership_data/lowly_cited_readership.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "        readership_lcp = get_df(lines)\n",
    "    \n",
    "    readership = pd.concat([readership_hcp, readership_mcp, readership_lcp])\n",
    "    \n",
    "    papers = pd.merge(papers, readership.drop(['doi'],axis=1), on='eid', how='left')\n",
    "    \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read_per_cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.768178Z",
     "start_time": "2023-06-04T02:14:57.765437Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.169517Z",
     "iopub.status.busy": "2024-02-17T12:30:49.169386Z",
     "iopub.status.idle": "2024-02-17T12:30:49.172382Z",
     "shell.execute_reply": "2024-02-17T12:30:49.171974Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.169505Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_read_per_cite_df(df):\n",
    "    for year in range(2016,2023):\n",
    "        df[f'read_percite_{year}'] = (df[f'cumulative_reader_{year}'] +1) / (df['c_history'].map(lambda l: sum(l[:year-2015])) + 1)\n",
    "    return df\n",
    "\n",
    "def assign_read_percite(papers):\n",
    "    return calc_read_per_cite_df(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## disuption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.775145Z",
     "start_time": "2023-06-04T02:14:57.769213Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.173015Z",
     "iopub.status.busy": "2024-02-17T12:30:49.172888Z",
     "iopub.status.idle": "2024-02-17T12:30:49.178709Z",
     "shell.execute_reply": "2024-02-17T12:30:49.178342Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.173003Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_disruption():\n",
    "    eids_2016 = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/paper_detail_2016/eid_2016.pickle')\n",
    "    citations_gb = pd.read_pickle('/disks/qnap2/shared/scopus_2022/citations_gb.pickle')\n",
    "    citations_gb_2016 = citations_gb.reindex(eids_2016.values)\n",
    "    citations_gb_2016 = citations_gb_2016.dropna(subset=['target'])\n",
    "\n",
    "    idxs = citations_gb_2016.index.to_list()\n",
    "    sources = citations_gb_2016['source'].map(lambda x: set(x) if type(x) == list else set()).to_list()\n",
    "    targets = citations_gb_2016['target'].map(lambda x: set(x) if type(x) == list else set()).to_list()\n",
    "    targets_all_dic = citations_gb['target'].map(lambda x: set(x) if type(x) == list else set()).to_dict()\n",
    "\n",
    "    citations_2016 = pd.DataFrame(list(set(\n",
    "        [\n",
    "            (s,idx,1) if targets_all_dic.get(s,set()) & t_set else (s,idx,0) \n",
    "            for idx,s_set,t_set in zip(idxs,sources,targets) \n",
    "            for s in s_set\n",
    "        ]))\n",
    "    ,columns=['source','target','is_develop'])\n",
    "    citations_2016.to_pickle('/disks/qnap2/data/t-miura/2023_readership/paper_detail_2016/citations_2016_disruptiveness_2022_dropNaN.pickle')\n",
    "\n",
    "    def calc_D_nok(n_disrupt,n_develop):\n",
    "        if n_disrupt+n_develop == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return (n_disrupt-n_develop) / (n_disrupt+n_develop)\n",
    "\n",
    "\n",
    "    D = {}\n",
    "    for eid_2016, df in tqdm(citations_2016.groupby('target')):\n",
    "        n_develop = df['is_develop'].sum()\n",
    "        n_disrupt = len(df) - n_develop\n",
    "        D[eid_2016] = calc_D_nok(n_disrupt, n_develop)\n",
    "    pd.Series(D, name='D_nok').to_pickle('/disks/qnap2/data/t-miura/2023_readership/paper_detail_2016/D_nok_2016_2022_dropNaN.pickle')\n",
    "    \n",
    "def assign_disruption(papers):\n",
    "    papers = pd.merge(papers, pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/paper_detail_2016/D_nok_2016_2022_dropNaN.pickle'), left_on='eid', right_index=True, how='left')\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.780729Z",
     "start_time": "2023-06-04T02:14:57.776201Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.179312Z",
     "iopub.status.busy": "2024-02-17T12:30:49.179178Z",
     "iopub.status.idle": "2024-02-17T12:30:49.183620Z",
     "shell.execute_reply": "2024-02-17T12:30:49.183257Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.179300Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_capacity(papers):\n",
    "    c_histories = pd.read_pickle('/disks/qnap_m/rawdata/scopus/2022/paper_detail/c_history.pickle').to_dict() \n",
    "    years = pd.read_pickle('/disks/qnap2/shared/scopus_2022/paper_detail/year.pickle').to_dict()\n",
    "    refs = pd.read_pickle('/disks/qnap2/shared/scopus_2022/citations_gb.pickle')['target'].to_dict()\n",
    "\n",
    "    def calc_capacity(eid):\n",
    "        _refs = refs.get(eid,[])\n",
    "        if type(_refs) != list:\n",
    "            return np.nan\n",
    "        # 変更点\n",
    "        c_ref_star_mean = np.exp(np.mean([np.log(sum(c_histories[_ref_eid][:years[eid]-years[_ref_eid]]) + 1) for _ref_eid in _refs])) #publication citation\n",
    "        c_ref_inf_mean = np.exp(np.mean([np.log(sum(c_histories[_ref_eid]) + 1) for _ref_eid in _refs])) #2022 citation(ultimate impact)\n",
    "\n",
    "        return 1-(c_ref_star_mean/c_ref_inf_mean)\n",
    "    \n",
    "    papers = papers.assign(capacity=lambda df: df['eid'].map(calc_capacity))\n",
    "    \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018, 2021 year, HCP, MCP, LCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.786991Z",
     "start_time": "2023-06-04T02:14:57.781832Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.184228Z",
     "iopub.status.busy": "2024-02-17T12:30:49.184098Z",
     "iopub.status.idle": "2024-02-17T12:30:49.188944Z",
     "shell.execute_reply": "2024-02-17T12:30:49.188586Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.184216Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_hcp_mcp_lcp(c, c_top10p, c_bottom50p):\n",
    "    \n",
    "    if np.isnan(c): return 'invalid citaiton'\n",
    "    elif c>c_top10p: return 'top'\n",
    "    elif c<c_bottom50p: return 'bottom'\n",
    "    else: return 'middle'\n",
    "\n",
    "def get_hcp_mcp_lcp(papers, year):\n",
    "    \n",
    "    if year == 2018:\n",
    "        citation_col = 'c_history_sum_2018'\n",
    "    elif year == 2021:\n",
    "        citation_col = 'c_history_sum'\n",
    "    else:\n",
    "        raise('year is not 2018 or 2021')\n",
    "    \n",
    "    dfs = []\n",
    "    for cluster in sorted(papers['partition_1e-06'].dropna().unique()):\n",
    "        papers_cluster = papers[papers['partition_1e-06']==cluster].copy()\n",
    "\n",
    "        if cluster == -1: \n",
    "            papers_cluster[f'label_hml_{year}'] = ['invalid cluster' for i in range(len(papers_cluster))]\n",
    "        else:    \n",
    "            c_normalized_top10p = np.percentile(papers_cluster[citation_col].dropna(), 90)\n",
    "            c_normalized_bottom50p = np.percentile(papers_cluster[citation_col].dropna(), 50)\n",
    "            print(cluster, c_normalized_top10p, c_normalized_bottom50p)\n",
    "            papers_cluster[f'label_hml_{year}'] = papers_cluster[citation_col].map(lambda x: label_hcp_mcp_lcp(x, c_normalized_top10p, c_normalized_bottom50p))\n",
    "\n",
    "        dfs.append(papers_cluster)\n",
    "    papers = pd.concat(dfs).reindex(papers.index)\n",
    "    return papers\n",
    "    \n",
    "def assign_hcp_mcp_lcp(papers):\n",
    "    papers = get_hcp_mcp_lcp(papers, year=2018)\n",
    "    papers = get_hcp_mcp_lcp(papers, year=2021)\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auth_prestige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:14:57.790308Z",
     "start_time": "2023-06-04T02:14:57.787941Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.191079Z",
     "iopub.status.busy": "2024-02-17T12:30:49.190938Z",
     "iopub.status.idle": "2024-02-17T12:30:49.193828Z",
     "shell.execute_reply": "2024-02-17T12:30:49.193447Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.191067Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_auth_prestige(papers):\n",
    "    authid_medcite = pd.read_pickle('/disks/qnap2/data/t-miura/2022_storyteller/project1/IC2s2_CD15/regression/authid_medcite.pickle')\n",
    "    papers = papers.assign(auth_prestige = lambda df: df['authids'].map(lambda authids: np.nanmax([0]+[authid_medcite[2015].get(authid,0) for authid in authids])))\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:05.683762Z",
     "start_time": "2023-06-04T02:46:05.678638Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.194417Z",
     "iopub.status.busy": "2024-02-17T12:30:49.194287Z",
     "iopub.status.idle": "2024-02-17T12:30:49.197691Z",
     "shell.execute_reply": "2024-02-17T12:30:49.197351Z",
     "shell.execute_reply.started": "2024-02-17T12:30:49.194405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eid', 'authids', 'subjs', 'doi', 'doctype', 'journal', 'c_history',\n",
       "       'c_history_sum', 'c_normalized_1e-06', 'CD', 'partition_1e-06',\n",
       "       'c_history_sum_2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:15:20.766633Z",
     "start_time": "2023-06-04T02:14:57.795455Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-17T12:30:49.198272Z",
     "iopub.status.busy": "2024-02-17T12:30:49.198145Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_jif(papers_2016, year=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:15:40.608625Z",
     "start_time": "2023-06-04T02:15:20.767722Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_partition(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:15:56.608139Z",
     "start_time": "2023-06-04T02:15:40.609755Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_readership(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:16:04.882905Z",
     "start_time": "2023-06-04T02:15:56.609308Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_read_percite(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:21:54.461755Z",
     "start_time": "2023-06-04T02:16:04.883998Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_auth_prestige(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:21:55.902381Z",
     "start_time": "2023-06-04T02:21:54.463572Z"
    }
   },
   "outputs": [],
   "source": [
    "get_disruption()\n",
    "papers_2016 = assign_disruption(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:22:24.337681Z",
     "start_time": "2023-06-04T02:21:55.903828Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_hcp_mcp_lcp(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:22:24.668992Z",
     "start_time": "2023-06-04T02:22:24.339346Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016.value_counts(['label_hml_2018','label_hml_2021'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:05.676662Z",
     "start_time": "2023-06-04T02:22:24.670219Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = assign_capacity(papers_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:05.683762Z",
     "start_time": "2023-06-04T02:46:05.678638Z"
    }
   },
   "outputs": [],
   "source": [
    "print(papers_2016.shape)\n",
    "papers_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:05.709158Z",
     "start_time": "2023-06-04T02:46:05.684897Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:17.197664Z",
     "start_time": "2023-06-04T02:46:05.711399Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "papers = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all.pickle')\n",
    "print(papers.shape)\n",
    "_ = papers[papers['cumulative_reader_2018'].notna()]\n",
    "print(len(_))\n",
    "_ = _[_['cumulative_reader_2021'].notna()]\n",
    "print(len(_)) # 85.4%にreadershipがある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrow down the data to be used in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readership valid(exist + 2018<=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:25.809407Z",
     "start_time": "2023-06-04T02:46:17.201297Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016 = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all.pickle')\n",
    "\n",
    "print('2018年のreadershipが2021年より多い場合: ', (papers_2016['cumulative_reader_2018']>papers_2016['cumulative_reader_2021']).sum())\n",
    "valid_eids = papers_2016[papers_2016['cumulative_reader_2018']<=papers_2016['cumulative_reader_2021']]['eid'] #ちゃんとしたreadershipを持つidたち\n",
    "\n",
    "papers_2016_validread = papers_2016[papers_2016['eid'].isin(valid_eids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:25.814185Z",
     "start_time": "2023-06-04T02:46:25.810794Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:35.465320Z",
     "start_time": "2023-06-04T02:46:25.815323Z"
    }
   },
   "outputs": [],
   "source": [
    "print(papers_2016_validread.shape)\n",
    "papers_2016_validread.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all_validread.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T07:38:14.408548Z",
     "start_time": "2023-06-08T07:38:03.535387Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_2016_validread = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all_validread.pickle')\n",
    "\n",
    "print(papers_2016_validread.shape)\n",
    "_ = papers_2016_validread[papers_2016_validread['cumulative_reader_2018'].notna()]\n",
    "print(len(_))\n",
    "_ = _[_['cumulative_reader_2021'].notna()]\n",
    "print(len(_)) # 85.4%にreadershipがある\n",
    "\n",
    "papers_2016_validread.value_counts(['label_hml_2021'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_2016_validread[papers_2016_validread['cumulative_reader_2018']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T02:46:40.344783Z",
     "start_time": "2023-06-04T02:46:35.467132Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers_2016_validread = pd.read_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_2016_all_validread.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## citation + field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slowとlow(2018では同じ)\n",
    "papers_slow_lowmatched2018 = []\n",
    "papers_low_slowmatched2018 = []\n",
    "# slowとfast(2021では同じ)\n",
    "papers_slow_fastmatched2021 = []\n",
    "papers_fast_slowmatched2021 = []\n",
    "\n",
    "for partition in tqdm(sorted(papers_2016_validread['partition_1e-06'].unique())):\n",
    "    df_slow = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_1e-06` == {partition}')\n",
    "    df_fast = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['top']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_1e-06` == {partition}')\n",
    "    df_low = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['middle','bottom']))].query(f'`partition_1e-06` == {partition}')\n",
    "    \n",
    "    print(partition, len(df_slow), len(df_fast), len(df_low))\n",
    "    \n",
    "    # 2018で揃えたslow vs low\n",
    "    for c2018, count in df_slow['c_history_sum_2018'].value_counts().items():\n",
    "        n_sample = min([len(df_slow.query('c_history_sum_2018 == @c2018')),len(df_low.query('c_history_sum_2018 == @c2018'))])\n",
    "        papers_slow_lowmatched2018.append(df_slow.query('c_history_sum_2018 == @c2018').sample(n_sample, random_state=42))\n",
    "        papers_low_slowmatched2018.append(df_low.query('c_history_sum_2018 == @c2018').sample(n_sample, random_state=42))\n",
    "    \n",
    "    # 2021で揃えたslow vs fast\n",
    "    for c2021, count in df_slow['c_history_sum'].value_counts().items():\n",
    "        n_sample = min([len(df_slow.query('c_history_sum == @c2021')),len(df_fast.query('c_history_sum == @c2021'))])\n",
    "        papers_slow_fastmatched2021.append(df_slow.query('c_history_sum == @c2021').sample(n_sample, random_state=42))\n",
    "        papers_fast_slowmatched2021.append(df_fast.query('c_history_sum == @c2021').sample(n_sample, random_state=42))\n",
    "\n",
    "papers_slow_lowmatched2018 = pd.concat(papers_slow_lowmatched2018)\n",
    "papers_low_slowmatched2018 = pd.concat(papers_low_slowmatched2018)\n",
    "papers_slow_fastmatched2021 = pd.concat(papers_slow_fastmatched2021)\n",
    "papers_fast_slowmatched2021 = pd.concat(papers_fast_slowmatched2021)\n",
    "\n",
    "print(papers_slow_lowmatched2018.shape)\n",
    "print(papers_low_slowmatched2018.shape)\n",
    "print(papers_slow_fastmatched2021.shape)\n",
    "print(papers_fast_slowmatched2021.shape)\n",
    "\n",
    "papers_slow_lowmatched2018.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_lowmatched2018.pickle')\n",
    "papers_low_slowmatched2018.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_low_1e-06_slowmatched2018.pickle')\n",
    "papers_slow_fastmatched2021.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_fastmatched2021.pickle')\n",
    "papers_fast_slowmatched2021.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_fast_1e-06_slowmatched2021.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## citation + field + journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers_slow_lowmatched2018_journal = []\n",
    "papers_low_slowmatched2018_journal = []\n",
    "papers_slow_fastmatched2021_journal = []\n",
    "papers_fast_slowmatched2021_journal = []\n",
    "\n",
    "matched_eid_low_slowmatched = set()\n",
    "matched_eid_fast_slowmatched = set()\n",
    "\n",
    "for partition in tqdm(sorted(papers_2016_validread['partition_1e-06'].unique())):\n",
    "    df_slow = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_1e-06` == {partition}')\n",
    "    df_fast = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['top']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_1e-06` == {partition}')\n",
    "    df_low = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['middle','bottom']))].query(f'`partition_1e-06` == {partition}')\n",
    "            \n",
    "# 2018で揃えたslow vs low\n",
    "    for eid, c2018, journal in df_slow[['eid', 'c_history_sum_2018','journal']].values:\n",
    "        df_low_target = df_low.query('c_history_sum_2018 == @c2018').query('journal == @journal')\n",
    "        if len(df_low_target) != 0:\n",
    "            papers_slow_lowmatched2018_journal.append(df_slow.query('eid == @eid'))\n",
    "            row = df_low_target.sample(1, random_state=42)\n",
    "            papers_low_slowmatched2018_journal.append(row)\n",
    "            matched_eid_low_slowmatched.add(row['eid'].values[0])        \n",
    "        \n",
    "    # 2021で揃えたslow vs fast\n",
    "    for eid, c2021, journal in df_slow[['eid', 'c_history_sum','journal']].values:\n",
    "        df_fast_target = df_fast.query('c_history_sum == @c2021').query('journal == @journal')\n",
    "        if len(df_fast_target) != 0:\n",
    "            papers_slow_fastmatched2021_journal.append(df_slow.query('eid == @eid'))\n",
    "            row = df_fast_target.sample(1, random_state=42)\n",
    "            papers_fast_slowmatched2021_journal.append(row)\n",
    "            matched_eid_fast_slowmatched.add(row['eid'].values[0])\n",
    "\n",
    "papers_slow_lowmatched2018_journal = pd.concat(papers_slow_lowmatched2018_journal)\n",
    "papers_low_slowmatched2018_journal = pd.concat(papers_low_slowmatched2018_journal)\n",
    "papers_slow_fastmatched2021_journal = pd.concat(papers_slow_fastmatched2021_journal)\n",
    "papers_fast_slowmatched2021_journal = pd.concat(papers_fast_slowmatched2021_journal)\n",
    "\n",
    "print(papers_slow_lowmatched2018_journal.shape)\n",
    "print(papers_low_slowmatched2018_journal.shape)\n",
    "print(papers_slow_fastmatched2021_journal.shape)\n",
    "print(papers_fast_slowmatched2021_journal.shape)\n",
    "\n",
    "papers_slow_lowmatched2018_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_lowmatched2018_journal.pickle')\n",
    "papers_low_slowmatched2018_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_low_1e-06_slowmatched2018_journal.pickle')\n",
    "papers_slow_fastmatched2021_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_fastmatched2021_journal.pickle')\n",
    "papers_fast_slowmatched2021_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_fast_1e-06_slowmatched2021_journal.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## citation + topic + journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_slow_lowmatched2018_journal = []\n",
    "papers_low_slowmatched2018_journal = []\n",
    "papers_slow_fastmatched2021_journal = []\n",
    "papers_fast_slowmatched2021_journal = []\n",
    "\n",
    "matched_eid_low_slowmatched = set()\n",
    "matched_eid_fast_slowmatched = set()\n",
    "\n",
    "for partition in sorted(papers_2016_validread['partition_0.0005'].unique()):\n",
    "    df_slow = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_0.0005` == {partition}')\n",
    "    df_fast = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['top']))&(papers_2016_validread['label_hml_2021'].isin(['top']))].query(f'`partition_0.0005` == {partition}')\n",
    "    df_low = papers_2016_validread[(papers_2016_validread['label_hml_2018'].isin(['middle','bottom']))&(papers_2016_validread['label_hml_2021'].isin(['middle','bottom']))].query(f'`partition_0.0005` == {partition}')\n",
    "            \n",
    "# 2018で揃えたslow vs low\n",
    "    for eid, c2018, journal in df_slow[['eid', 'c_history_sum_2018','journal']].values:\n",
    "        df_low_target = df_low.query('c_history_sum_2018 == @c2018').query('journal == @journal')\n",
    "        if len(df_low_target) != 0:\n",
    "            papers_slow_lowmatched2018_journal.append(df_slow.query('eid == @eid'))\n",
    "            row = df_low_target.sample(1, random_state=42)\n",
    "            papers_low_slowmatched2018_journal.append(row)\n",
    "            matched_eid_low_slowmatched.add(row['eid'].values[0])        \n",
    "        \n",
    "    # 2021で揃えたslow vs fast\n",
    "    for eid, c2021, journal in df_slow[['eid', 'c_history_sum','journal']].values:\n",
    "        df_fast_target = df_fast.query('c_history_sum == @c2021').query('journal == @journal')\n",
    "        if len(df_fast_target) != 0:\n",
    "            papers_slow_fastmatched2021_journal.append(df_slow.query('eid == @eid'))\n",
    "            row = df_fast_target.sample(1, random_state=42)\n",
    "            papers_fast_slowmatched2021_journal.append(row)\n",
    "            matched_eid_fast_slowmatched.add(row['eid'].values[0])\n",
    "    if partition % 1000 == 0:\n",
    "        print(partition)\n",
    "\n",
    "papers_slow_lowmatched2018_journal = pd.concat(papers_slow_lowmatched2018_journal)\n",
    "papers_low_slowmatched2018_journal = pd.concat(papers_low_slowmatched2018_journal)\n",
    "papers_slow_fastmatched2021_journal = pd.concat(papers_slow_fastmatched2021_journal)\n",
    "papers_fast_slowmatched2021_journal = pd.concat(papers_fast_slowmatched2021_journal)\n",
    "\n",
    "print(papers_slow_lowmatched2018_journal.shape)\n",
    "print(papers_low_slowmatched2018_journal.shape)\n",
    "print(papers_slow_fastmatched2021_journal.shape)\n",
    "print(papers_fast_slowmatched2021_journal.shape)\n",
    "\n",
    "papers_slow_lowmatched2018_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_lowmatched2018_journal_topic.pickle')\n",
    "papers_low_slowmatched2018_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_low_1e-06_slowmatched2018_journal_topic.pickle')\n",
    "papers_slow_fastmatched2021_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_slow_1e-06_fastmatched2021_journal_topic.pickle')\n",
    "papers_fast_slowmatched2021_journal.to_pickle('/disks/qnap2/data/t-miura/2023_readership/final_paper/papers_fast_1e-06_slowmatched2021_journal_topic.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
